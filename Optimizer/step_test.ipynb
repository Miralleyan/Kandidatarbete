{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 43\u001B[0m\n\u001B[0;32m     39\u001B[0m kde_mat \u001B[38;5;241m=\u001B[39m K((data\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m-\u001B[39m regression_model(l, x\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))) \u001B[38;5;241m/\u001B[39m h)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m#a = torch.sum(kde_mat, dim=0)\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mKDENLLLoss\u001B[39m(m):\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m(torch\u001B[38;5;241m.\u001B[39mmatmul(kde_mat, m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m/\u001B[39m (M\u001B[38;5;241m*\u001B[39mh))\u001B[38;5;241m.\u001B[39mlog()\u001B[38;5;241m.\u001B[39msum()\n",
      "Cell \u001B[1;32mIn[24], line 43\u001B[0m\n\u001B[0;32m     39\u001B[0m kde_mat \u001B[38;5;241m=\u001B[39m K((data\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m-\u001B[39m regression_model(l, x\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))) \u001B[38;5;241m/\u001B[39m h)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m#a = torch.sum(kde_mat, dim=0)\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mKDENLLLoss\u001B[39m(m):\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m(torch\u001B[38;5;241m.\u001B[39mmatmul(kde_mat, m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m/\u001B[39m (M\u001B[38;5;241m*\u001B[39mh))\u001B[38;5;241m.\u001B[39mlog()\u001B[38;5;241m.\u001B[39msum()\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_measure as pm\n",
    "import numpy as np\n",
    "N = 5 # number of atoms\n",
    "M = 1000 # Number of datapoints\n",
    "verbose = True\n",
    "dev = 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def regression_model(a,x):\n",
    "    return a+x\n",
    "\n",
    "x = torch.linspace(0, 10, M)\n",
    "data = regression_model(torch.randn(M).to(dev) - 2, x)\n",
    "#data = -2 + x.view(-1,1) + torch.from_numpy(np.random.normal(0,1,(M,1))).float() # The way of the Sergei\n",
    "\n",
    "w = torch.rand(N,dtype=torch.float).to(dev)\n",
    "w = torch.nn.parameter.Parameter(w/w.sum())\n",
    "l = torch.linspace(-5, 1, N, requires_grad=False).to(dev)\n",
    "\n",
    "index = []\n",
    "for i in range(M):\n",
    "    ab = (regression_model(l, x[i]) - data[i]).abs()\n",
    "    index.append(torch.argmin(ab))\n",
    "\n",
    "def NLLLoss(m:list[pm.Measure]):\n",
    "    return -(m[0].weights[index]).log().sum()\n",
    "\n",
    "#sd = (l[index] - data)**2\n",
    "def WardLoss(w):\n",
    "    return sum(sd * w[index])\n",
    "\n",
    "def K(d):\n",
    "        return 1/np.sqrt(2*np.pi)*np.exp(-d**2/2)\n",
    "h=1.06*M**(-1/5)\n",
    "# K( (y - yj) / h )\n",
    "kde_mat = K((data.view(-1,1) - regression_model(l, x.view(-1,1))) / h)\n",
    "\n",
    "#a = torch.sum(kde_mat, dim=0)\n",
    "\n",
    "def KDENLLLoss(m):\n",
    "    return -(torch.matmul(kde_mat, m[0].weights.view(-1,1)) / (M*h)).log().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0          Loss: 9536.010742188 LR: 0.100000000\n",
      "Epoch: 1          Loss: 9337.510742188 LR: 0.100000000\n",
      "Epoch: 2          Loss: 9151.926757812 LR: 0.100000000\n",
      "Epoch: 3          Loss: 9035.953125000 LR: 0.100000000\n",
      "Epoch: 4          Loss: 8997.308593750 LR: 0.100000000\n",
      "Epoch: 5          Lr was reduced to: 0.070000000\n",
      "Epoch: 6          Loss: 8957.161132812 LR: 0.070000000\n",
      "Epoch: 7          Loss: 8941.557617188 LR: 0.070000000\n",
      "Epoch: 8          Lr was reduced to: 0.049000000\n",
      "Epoch: 9          Lr was reduced to: 0.034300000\n",
      "Epoch: 10         Lr was reduced to: 0.024010000\n",
      "Epoch: 11         Loss: 8923.373046875 LR: 0.024010000\n",
      "Epoch: 12         Lr was reduced to: 0.016807000\n",
      "Epoch: 13         Loss: 8910.690429688 LR: 0.016807000\n",
      "Epoch: 14         Lr was reduced to: 0.011764900\n",
      "Epoch: 15         Lr was reduced to: 0.008235430\n",
      "Epoch: 16         Loss: 8910.151367188 LR: 0.008235430\n",
      "Epoch: 17         Lr was reduced to: 0.005764801\n",
      "Epoch: 18         Loss: 8909.591796875 LR: 0.005764801\n",
      "Epoch: 19         Loss: 8908.467773438 LR: 0.005764801\n",
      "Epoch: 20         Loss: 8908.069335938 LR: 0.005764801\n",
      "Epoch: 21         Loss: 8907.013671875 LR: 0.005764801\n",
      "Epoch: 22         Loss: 8906.712890625 LR: 0.005764801\n",
      "Epoch: 23         Loss: 8905.722656250 LR: 0.005764801\n",
      "Epoch: 24         Loss: 8905.525390625 LR: 0.005764801\n",
      "Epoch: 25         Loss: 8904.601562500 LR: 0.005764801\n",
      "Epoch: 26         Loss: 8904.510742188 LR: 0.005764801\n",
      "Epoch: 27         Loss: 8903.648437500 LR: 0.005764801\n",
      "Epoch: 28         Loss: 8903.619140625 LR: 0.005764801\n",
      "Epoch: 29         Loss: 8902.837890625 LR: 0.005764801\n",
      "Epoch: 30         Loss did not change (8902.837890625)\n",
      "1853314381120\n",
      "1853338801664\n",
      "---\n",
      "Epoch: 31         Loss: 8902.118164062 LR: 0.005764801\n",
      "Epoch: 32         Lr was reduced to: 0.004035361\n",
      "Epoch: 33         Loss: 8901.959960938 LR: 0.004035361\n",
      "Epoch: 34         Loss: 8901.702148438 LR: 0.004035361\n",
      "Epoch: 35         Loss: 8901.558593750 LR: 0.004035361\n",
      "Epoch: 36         Lr was reduced to: 0.002824752\n",
      "Epoch: 37         Lr was reduced to: 0.001977327\n",
      "Epoch: 38         Loss: 8901.462890625 LR: 0.001977327\n",
      "Epoch: 39         Loss: 8901.303710938 LR: 0.001977327\n",
      "Epoch: 40         Loss: 8901.289062500 LR: 0.001977327\n",
      "Epoch: 41         Loss: 8901.137695312 LR: 0.001977327\n",
      "Epoch: 42         Loss: 8901.129882812 LR: 0.001977327\n",
      "Epoch: 43         Loss: 8900.986328125 LR: 0.001977327\n",
      "Epoch: 44         Loss did not change (8900.986328125)\n",
      "1853338520192\n",
      "1853338552000\n",
      "---\n",
      "Epoch: 45         Loss: 8900.849609375 LR: 0.001977327\n",
      "Epoch: 46         Lr was reduced to: 0.001384129\n",
      "Epoch: 47         Loss: 8900.819335938 LR: 0.001384129\n",
      "Epoch: 48         Loss: 8900.760742188 LR: 0.001384129\n",
      "Epoch: 49         Loss: 8900.738281250 LR: 0.001384129\n",
      "Epoch: 50         Loss: 8900.682617188 LR: 0.001384129\n",
      "Epoch: 51         Loss: 8900.657226562 LR: 0.001384129\n",
      "Epoch: 52         Loss: 8900.606445312 LR: 0.001384129\n",
      "Epoch: 53         Loss: 8900.587890625 LR: 0.001384129\n",
      "Epoch: 54         Loss: 8900.541015625 LR: 0.001384129\n",
      "Epoch: 55         Loss: 8900.524414062 LR: 0.001384129\n",
      "Epoch: 56         Loss: 8900.479492188 LR: 0.001384129\n",
      "Epoch: 57         Loss: 8900.468750000 LR: 0.001384129\n",
      "Epoch: 58         Loss: 8900.427734375 LR: 0.001384129\n",
      "Epoch: 59         Lr was reduced to: 0.000968890\n",
      "Epoch: 60         Lr was reduced to: 0.000678223\n",
      "Epoch: 61         Loss: 8900.416015625 LR: 0.000678223\n",
      "Epoch: 62         Loss: 8900.402343750 LR: 0.000678223\n",
      "Epoch: 63         Loss: 8900.392578125 LR: 0.000678223\n",
      "Epoch: 64         Loss: 8900.378906250 LR: 0.000678223\n",
      "Epoch: 65         Loss: 8900.370117188 LR: 0.000678223\n",
      "Epoch: 66         Loss: 8900.358398438 LR: 0.000678223\n",
      "Epoch: 67         Loss: 8900.350585938 LR: 0.000678223\n",
      "Epoch: 68         Loss: 8900.338867188 LR: 0.000678223\n",
      "Epoch: 69         Loss: 8900.332031250 LR: 0.000678223\n",
      "Epoch: 70         Loss: 8900.320312500 LR: 0.000678223\n",
      "Epoch: 71         Loss: 8900.315429688 LR: 0.000678223\n",
      "Epoch: 72         Loss: 8900.305664062 LR: 0.000678223\n",
      "Epoch: 73         Loss: 8900.300781250 LR: 0.000678223\n",
      "Epoch: 74         Loss: 8900.291015625 LR: 0.000678223\n",
      "Epoch: 75         Loss: 8900.287109375 LR: 0.000678223\n",
      "Epoch: 76         Lr was reduced to: 0.000474756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m measure \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mMeasure(locations\u001B[38;5;241m=\u001B[39ml, weights\u001B[38;5;241m=\u001B[39mw, device\u001B[38;5;241m=\u001B[39mdev)\n\u001B[0;32m      2\u001B[0m opt \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mOptimizer([measure], lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-1\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mopt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mKDENLLLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol_const\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot()\n\u001B[0;32m      7\u001B[0m mu\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m \u001B[38;5;66;03m#Create true values\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive - Chalmers\\År 3\\Kandidatarbete\\Python Git\\Optimizer\\pytorch_measure.py:242\u001B[0m, in \u001B[0;36mOptimizer.minimize\u001B[1;34m(self, loss_fn, max_epochs, smallest_lr, verbose, tol_supp, tol_const, print_freq)\u001B[0m\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<10\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Lr was reduced to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlr\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.9f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m loss_old \u001B[38;5;241m==\u001B[39m loss_new \u001B[38;5;129;01mand\u001B[39;00m verbose:\n\u001B[1;32m--> 242\u001B[0m     \u001B[38;5;28;43mprint\u001B[39;49m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<10\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Loss did not change (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_new\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeasures))\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mid\u001B[39m(old_measures))\n",
      "File \u001B[1;32m~\\OneDrive - Chalmers\\År 3\\Kandidatarbete\\Python Git\\Optimizer\\pytorch_measure.py:242\u001B[0m, in \u001B[0;36mOptimizer.minimize\u001B[1;34m(self, loss_fn, max_epochs, smallest_lr, verbose, tol_supp, tol_const, print_freq)\u001B[0m\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<10\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Lr was reduced to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlr\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.9f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m loss_old \u001B[38;5;241m==\u001B[39m loss_new \u001B[38;5;129;01mand\u001B[39;00m verbose:\n\u001B[1;32m--> 242\u001B[0m     \u001B[38;5;28;43mprint\u001B[39;49m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<10\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Loss did not change (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_new\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeasures))\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mid\u001B[39m(old_measures))\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "measure = pm.Measure(locations=l, weights=w, device=dev)\n",
    "opt = pm.Optimizer([measure], lr=1e-1)\n",
    "opt.minimize(KDENLLLoss, verbose=True, print_freq=1, max_epochs=1000, tol_const=1e-2)\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "mu=0 #Create true values\n",
    "sigma=1\n",
    "xs = l.detach()\n",
    "y=1/(np.sqrt(2*np.pi)*sigma)*torch.exp(-(xs+2-mu)**2/(2*sigma**2))\n",
    "y/=sum(y) #Normalize\n",
    "\n",
    "\n",
    "measure.visualize()\n",
    "#plt.bar(l-0.1, torch.sum(kde_mat, dim=0)/torch.sum(kde_mat), zorder=0, width=0.1)\n",
    "plt.scatter(xs, y, zorder=2, label=\"True distribution\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "#LR         to 1e-4             to 1e-5\n",
    "#1e-3  -  2147.958496094        2145.816650391\n",
    "#1e-2  -  2147.958496094        2145.816650391\n",
    "#1e-1  -  2149.463867188        2145.826660156"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TorchMeasure' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch_measure\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01ms\u001B[39;00m\n\u001B[0;32m      5\u001B[0m mes \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mTorchMeasure(l, w)\n\u001B[1;32m----> 6\u001B[0m opt \u001B[38;5;241m=\u001B[39m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMeasureMinimizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mNLLLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m opt\u001B[38;5;241m.\u001B[39mminimize()\n\u001B[0;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(xs, y, zorder\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[1;32m~\\OneDrive - Chalmers\\År 3\\Kandidatarbete\\Python Git\\Optimizer\\../Sergei\\torch_measure.py:215\u001B[0m, in \u001B[0;36mMeasureMinimizer.__init__\u001B[1;34m(self, mes, goal_fn, learning_rate, **goal_func_kwargs)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgoal_func_kwargs \u001B[38;5;241m=\u001B[39m goal_func_kwargs\n\u001B[0;32m    213\u001B[0m \u001B[38;5;66;03m# self.grad = None\u001B[39;00m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;66;03m# computed initial values:\u001B[39;00m\n\u001B[1;32m--> 215\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgoal_fn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmes, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgoal_func_kwargs)\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmes\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;66;03m# clear the gradients\u001B[39;00m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval\u001B[38;5;241m.\u001B[39mbackward() \u001B[38;5;66;03m# compute the gradient\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[30], line 29\u001B[0m, in \u001B[0;36mNLLLoss\u001B[1;34m(m)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mNLLLoss\u001B[39m(m:\u001B[38;5;28mlist\u001B[39m[pm\u001B[38;5;241m.\u001B[39mMeasure]):\n\u001B[1;32m---> 29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m(\u001B[43mm\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mweights[index])\u001B[38;5;241m.\u001B[39mlog()\u001B[38;5;241m.\u001B[39msum()\n",
      "\u001B[1;31mTypeError\u001B[0m: 'TorchMeasure' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../Sergei')\n",
    "import torch_measure as s\n",
    "\n",
    "mes = s.TorchMeasure(l, w)\n",
    "opt = s.MeasureMinimizer(mes, NLLLoss, learning_rate=1e-1)\n",
    "opt.minimize()\n",
    "\n",
    "\n",
    "plt.scatter(xs, y, zorder=2)\n",
    "plt.bar(l, mes.weights.detach())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
