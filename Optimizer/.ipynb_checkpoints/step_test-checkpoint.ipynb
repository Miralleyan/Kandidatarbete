{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_measure as pm\n",
    "import numpy as np\n",
    "N = 17 # number of weights\n",
    "M = 1000 # Number of datapoints\n",
    "verbose = True\n",
    "dev = 'cpu'\n",
    "\n",
    "def regression_model(a,x):\n",
    "    return a+x\n",
    "\n",
    "x = torch.linspace(0, 10, M)\n",
    "data = regression_model(torch.randn(M).to(dev) - 2, x)\n",
    "\n",
    "w = torch.ones(N,dtype=torch.float).to(dev)\n",
    "w = torch.nn.parameter.Parameter(w/w.sum())\n",
    "l = torch.linspace(-6, 2, N, requires_grad=False).to(dev)\n",
    "\n",
    "index = []\n",
    "for i in range(M):\n",
    "    ab = (regression_model(l, x[i]) - data[i]).abs()\n",
    "    index.append(torch.argmin(ab))\n",
    "\n",
    "\"\"\"\n",
    "def NLLLoss(m:list[pm.Measure]):\n",
    "    return -m[0].weights[index].log().sum()\n",
    "\"\"\"\n",
    "\n",
    "sd = (l[index] - data)**2\n",
    "def WardLoss(w):\n",
    "    return sum(sd * w[index])\n",
    "\n",
    "def K(d):\n",
    "        return 1/np.sqrt(2*np.pi)*np.exp(-d**2/2)\n",
    "h=1.06*M**(-1/5)\n",
    "kde_mat = K((regression_model(l, x.view(-1,1)) - data.view(-1,1)) / h)\n",
    "\n",
    "#a = torch.sum(kde_mat, dim=0)\n",
    "\n",
    "def KDENLLLoss(m):\n",
    "    return -(torch.matmul(kde_mat ,m[0].weights.view(-1,1))/(M*h)).log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0          Loss: 9044.5020  LR: 0.001000000\n",
      "Epoch: 1          Loss: 9041.1338  LR: 0.001000000\n",
      "Epoch: 2          Loss: 9037.7959  LR: 0.001000000\n",
      "Epoch: 3          Loss: 9034.4873  LR: 0.001000000\n",
      "Epoch: 4          Loss: 9031.2080  LR: 0.001000000\n",
      "Epoch: 5          Loss: 9027.9561  LR: 0.001000000\n",
      "Epoch: 6          Loss: 9024.7324  LR: 0.001000000\n",
      "Epoch: 7          Loss: 9021.5361  LR: 0.001000000\n",
      "Epoch: 8          Loss: 9018.3652  LR: 0.001000000\n",
      "Epoch: 9          Loss: 9015.2207  LR: 0.001000000\n",
      "Epoch: 10         Loss: 9012.1025  LR: 0.001000000\n",
      "Epoch: 11         Loss: 9009.0098  LR: 0.001000000\n",
      "Epoch: 12         Loss: 9005.9404  LR: 0.001000000\n",
      "Epoch: 13         Loss: 9002.8984  LR: 0.001000000\n",
      "Epoch: 14         Loss: 8999.8779  LR: 0.001000000\n",
      "Epoch: 15         Loss: 8996.8809  LR: 0.001000000\n",
      "Epoch: 16         Loss: 8993.9082  LR: 0.001000000\n",
      "Epoch: 17         Loss: 8990.9570  LR: 0.001000000\n",
      "Epoch: 18         Loss: 8988.0273  LR: 0.001000000\n",
      "Epoch: 19         Loss: 8985.1221  LR: 0.001000000\n",
      "Epoch: 20         Loss: 8982.2363  LR: 0.001000000\n",
      "Epoch: 21         Loss: 8979.3721  LR: 0.001000000\n",
      "Epoch: 22         Loss: 8976.5293  LR: 0.001000000\n",
      "Epoch: 23         Loss: 8973.7070  LR: 0.001000000\n",
      "Epoch: 24         Loss: 8970.9043  LR: 0.001000000\n",
      "Epoch: 25         Loss: 8968.1221  LR: 0.001000000\n",
      "Epoch: 26         Loss: 8965.3574  LR: 0.001000000\n",
      "Epoch: 27         Loss: 8962.6143  LR: 0.001000000\n",
      "Epoch: 28         Loss: 8959.8896  LR: 0.001000000\n",
      "Epoch: 29         Loss: 8957.1836  LR: 0.001000000\n",
      "Epoch: 30         Loss: 8954.4961  LR: 0.001000000\n",
      "Epoch: 31         Loss: 8951.8262  LR: 0.001000000\n",
      "Epoch: 32         Loss: 8949.1738  LR: 0.001000000\n",
      "Epoch: 33         Loss: 8946.5391  LR: 0.001000000\n",
      "Epoch: 34         Loss: 8943.9180  LR: 0.001000000\n",
      "Epoch: 35         Loss: 8941.3086  LR: 0.001000000\n",
      "Epoch: 36         Loss: 8938.7168  LR: 0.001000000\n",
      "Epoch: 37         Loss: 8936.1328  LR: 0.001000000\n",
      "Epoch: 38         Loss: 8933.5664  LR: 0.001000000\n",
      "Epoch: 39         Loss: 8931.0117  LR: 0.001000000\n",
      "Epoch: 40         Loss: 8928.4600  LR: 0.001000000\n",
      "Epoch: 41         Loss: 8925.9248  LR: 0.001000000\n",
      "Epoch: 42         Loss: 8923.3955  LR: 0.001000000\n",
      "Epoch: 43         Loss: 8920.8750  LR: 0.001000000\n",
      "Epoch: 44         Loss: 8918.3682  LR: 0.001000000\n",
      "Epoch: 45         Loss: 8915.8652  LR: 0.001000000\n",
      "Epoch: 46         Loss: 8913.3750  LR: 0.001000000\n",
      "Epoch: 47         Loss: 8910.8955  LR: 0.001000000\n",
      "Epoch: 48         Loss: 8908.4219  LR: 0.001000000\n",
      "Epoch: 49         Loss: 8905.9609  LR: 0.001000000\n",
      "Epoch: 50         Loss: 8903.5068  LR: 0.001000000\n",
      "Epoch: 51         Loss: 8901.0596  LR: 0.001000000\n",
      "Epoch: 52         Loss: 8898.6260  LR: 0.001000000\n",
      "Epoch: 53         Loss: 8896.1982  LR: 0.001000000\n",
      "Epoch: 54         Loss: 8893.7793  LR: 0.001000000\n",
      "Epoch: 55         Loss: 8891.3721  LR: 0.001000000\n",
      "Epoch: 56         Loss: 8888.9688  LR: 0.001000000\n",
      "Epoch: 57         Loss: 8886.5791  LR: 0.001000000\n",
      "Epoch: 58         Loss: 8884.1953  LR: 0.001000000\n",
      "Epoch: 59         Loss: 8881.8223  LR: 0.001000000\n",
      "Epoch: 60         Loss: 8879.4600  LR: 0.001000000\n",
      "Epoch: 61         Loss: 8877.1055  LR: 0.001000000\n",
      "Epoch: 62         Loss: 8874.7578  LR: 0.001000000\n",
      "Epoch: 63         Loss: 8872.4209  LR: 0.001000000\n",
      "Epoch: 64         Loss: 8870.0898  LR: 0.001000000\n",
      "Epoch: 65         Loss: 8867.7686  LR: 0.001000000\n",
      "Epoch: 66         Loss: 8865.4551  LR: 0.001000000\n",
      "Epoch: 67         Loss: 8863.1475  LR: 0.001000000\n",
      "Epoch: 68         Loss: 8860.8506  LR: 0.001000000\n",
      "Epoch: 69         Loss: 8858.5605  LR: 0.001000000\n",
      "Epoch: 70         Loss: 8856.2793  LR: 0.001000000\n",
      "Epoch: 71         Loss: 8854.0039  LR: 0.001000000\n",
      "Epoch: 72         Loss: 8851.7363  LR: 0.001000000\n",
      "Epoch: 73         Loss: 8849.4785  LR: 0.001000000\n",
      "Epoch: 74         Loss: 8847.2275  LR: 0.001000000\n",
      "Epoch: 75         Loss: 8844.9824  LR: 0.001000000\n",
      "Epoch: 76         Loss: 8842.7461  LR: 0.001000000\n",
      "Epoch: 77         Loss: 8840.5176  LR: 0.001000000\n",
      "Epoch: 78         Loss: 8838.2969  LR: 0.001000000\n",
      "Epoch: 79         Loss: 8836.0811  LR: 0.001000000\n",
      "Epoch: 80         Loss: 8833.8750  LR: 0.001000000\n",
      "Epoch: 81         Loss: 8831.6758  LR: 0.001000000\n",
      "Epoch: 82         Loss: 8829.4844  LR: 0.001000000\n",
      "Epoch: 83         Loss: 8827.2998  LR: 0.001000000\n",
      "Epoch: 84         Loss: 8825.1201  LR: 0.001000000\n",
      "Epoch: 85         Loss: 8822.9492  LR: 0.001000000\n",
      "Epoch: 86         Loss: 8820.7852  LR: 0.001000000\n",
      "Epoch: 87         Loss: 8818.6289  LR: 0.001000000\n",
      "Epoch: 88         Loss: 8816.4785  LR: 0.001000000\n",
      "Epoch: 89         Loss: 8814.3340  LR: 0.001000000\n",
      "Epoch: 90         Loss: 8812.1992  LR: 0.001000000\n",
      "Epoch: 91         Loss: 8810.0703  LR: 0.001000000\n",
      "Epoch: 92         Loss: 8807.9463  LR: 0.001000000\n",
      "Epoch: 93         Loss: 8805.8311  LR: 0.001000000\n",
      "Epoch: 94         Loss: 8803.7207  LR: 0.001000000\n",
      "Epoch: 95         Loss: 8801.6182  LR: 0.001000000\n",
      "Epoch: 96         Loss: 8799.5225  LR: 0.001000000\n",
      "Epoch: 97         Loss: 8797.4316  LR: 0.001000000\n",
      "Epoch: 98         Loss: 8795.3496  LR: 0.001000000\n",
      "Epoch: 99         Loss: 8793.2725  LR: 0.001000000\n",
      "Epoch: 100        Loss: 8791.2012  LR: 0.001000000\n",
      "Epoch: 101        Loss: 8789.1387  LR: 0.001000000\n",
      "Epoch: 102        Loss: 8787.0781  LR: 0.001000000\n",
      "Epoch: 103        Loss: 8785.0293  LR: 0.001000000\n",
      "Epoch: 104        Loss: 8782.9844  LR: 0.001000000\n",
      "Epoch: 105        Loss: 8780.9434  LR: 0.001000000\n",
      "Epoch: 106        Loss: 8778.9121  LR: 0.001000000\n",
      "Epoch: 107        Loss: 8776.8838  LR: 0.001000000\n",
      "Epoch: 108        Loss: 8774.8633  LR: 0.001000000\n",
      "Epoch: 109        Loss: 8772.8516  LR: 0.001000000\n",
      "Epoch: 110        Loss: 8770.8408  LR: 0.001000000\n",
      "Epoch: 111        Loss: 8768.8408  LR: 0.001000000\n",
      "Epoch: 112        Loss: 8766.8418  LR: 0.001000000\n",
      "Epoch: 113        Loss: 8764.8516  LR: 0.001000000\n",
      "Epoch: 114        Loss: 8762.8682  LR: 0.001000000\n",
      "Epoch: 115        Loss: 8760.8867  LR: 0.001000000\n",
      "Epoch: 116        Loss: 8758.9150  LR: 0.001000000\n",
      "Epoch: 117        Loss: 8756.9541  LR: 0.001000000\n",
      "Epoch: 118        Loss: 8755.0059  LR: 0.001000000\n",
      "Epoch: 119        Loss: 8753.0684  LR: 0.001000000\n",
      "Epoch: 120        Loss: 8751.1309  LR: 0.001000000\n",
      "Epoch: 121        Loss: 8749.2012  LR: 0.001000000\n",
      "Epoch: 122        Loss: 8747.2803  LR: 0.001000000\n",
      "Epoch: 123        Loss: 8745.3613  LR: 0.001000000\n",
      "Epoch: 124        Loss: 8743.4512  LR: 0.001000000\n",
      "Epoch: 125        Loss: 8741.5479  LR: 0.001000000\n",
      "Epoch: 126        Loss: 8739.6436  LR: 0.001000000\n",
      "Epoch: 127        Loss: 8737.7520  LR: 0.001000000\n",
      "Epoch: 128        Loss: 8735.8613  LR: 0.001000000\n",
      "Epoch: 129        Loss: 8733.9785  LR: 0.001000000\n",
      "Epoch: 130        Loss: 8732.1035  LR: 0.001000000\n",
      "Epoch: 131        Loss: 8730.2295  LR: 0.001000000\n",
      "Epoch: 132        Loss: 8728.3652  LR: 0.001000000\n",
      "Epoch: 133        Loss: 8726.5020  LR: 0.001000000\n",
      "Epoch: 134        Loss: 8724.6475  LR: 0.001000000\n",
      "Epoch: 135        Loss: 8722.7988  LR: 0.001000000\n",
      "Epoch: 136        Loss: 8720.9531  LR: 0.001000000\n",
      "Epoch: 137        Loss: 8719.1182  LR: 0.001000000\n",
      "Epoch: 138        Loss: 8717.2832  LR: 0.001000000\n",
      "Epoch: 139        Loss: 8715.4551  LR: 0.001000000\n",
      "Epoch: 140        Loss: 8713.6338  LR: 0.001000000\n",
      "Epoch: 141        Loss: 8711.8164  LR: 0.001000000\n",
      "Epoch: 142        Loss: 8710.0059  LR: 0.001000000\n",
      "Epoch: 143        Loss: 8708.2002  LR: 0.001000000\n",
      "Epoch: 144        Loss: 8706.3984  LR: 0.001000000\n",
      "Epoch: 145        Loss: 8704.6035  LR: 0.001000000\n",
      "Epoch: 146        Loss: 8702.8125  LR: 0.001000000\n",
      "Epoch: 147        Loss: 8701.0273  LR: 0.001000000\n",
      "Epoch: 148        Loss: 8699.2480  LR: 0.001000000\n",
      "Epoch: 149        Loss: 8697.4697  LR: 0.001000000\n",
      "Epoch: 150        Loss: 8695.7012  LR: 0.001000000\n",
      "Epoch: 151        Loss: 8693.9355  LR: 0.001000000\n",
      "Epoch: 152        Loss: 8692.1748  LR: 0.001000000\n",
      "Epoch: 153        Loss: 8690.4189  LR: 0.001000000\n",
      "Epoch: 154        Loss: 8688.6680  LR: 0.001000000\n",
      "Epoch: 155        Loss: 8686.9238  LR: 0.001000000\n",
      "Epoch: 156        Loss: 8685.1797  LR: 0.001000000\n",
      "Epoch: 157        Loss: 8683.4424  LR: 0.001000000\n",
      "Epoch: 158        Loss: 8681.7070  LR: 0.001000000\n",
      "Epoch: 159        Loss: 8679.9795  LR: 0.001000000\n",
      "Epoch: 160        Loss: 8678.2539  LR: 0.001000000\n",
      "Epoch: 161        Loss: 8676.5352  LR: 0.001000000\n",
      "Epoch: 162        Loss: 8674.8184  LR: 0.001000000\n",
      "Epoch: 163        Loss: 8673.1064  LR: 0.001000000\n",
      "Epoch: 164        Loss: 8671.3975  LR: 0.001000000\n",
      "Epoch: 165        Loss: 8669.6973  LR: 0.001000000\n",
      "Epoch: 166        Loss: 8668.0000  LR: 0.001000000\n",
      "Epoch: 167        Loss: 8666.3018  LR: 0.001000000\n",
      "Epoch: 168        Loss: 8664.6104  LR: 0.001000000\n",
      "Epoch: 169        Loss: 8662.9258  LR: 0.001000000\n",
      "Epoch: 170        Loss: 8661.2432  LR: 0.001000000\n",
      "Epoch: 171        Loss: 8659.5684  LR: 0.001000000\n",
      "Epoch: 172        Loss: 8657.8926  LR: 0.001000000\n",
      "Epoch: 173        Loss: 8656.2217  LR: 0.001000000\n",
      "Epoch: 174        Loss: 8654.5576  LR: 0.001000000\n",
      "Epoch: 175        Loss: 8652.8955  LR: 0.001000000\n",
      "Epoch: 176        Loss: 8651.2422  LR: 0.001000000\n",
      "Epoch: 177        Loss: 8649.5869  LR: 0.001000000\n",
      "Epoch: 178        Loss: 8647.9395  LR: 0.001000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179        Loss: 8646.2939  LR: 0.001000000\n",
      "Epoch: 180        Loss: 8644.6533  LR: 0.001000000\n",
      "Epoch: 181        Loss: 8643.0205  LR: 0.001000000\n",
      "Epoch: 182        Loss: 8641.3867  LR: 0.001000000\n",
      "Epoch: 183        Loss: 8639.7588  LR: 0.001000000\n",
      "Epoch: 184        Loss: 8638.1377  LR: 0.001000000\n",
      "Epoch: 185        Loss: 8636.5137  LR: 0.001000000\n",
      "Epoch: 186        Loss: 8634.8994  LR: 0.001000000\n",
      "Epoch: 187        Loss: 8633.2871  LR: 0.001000000\n",
      "Epoch: 188        Loss: 8631.6758  LR: 0.001000000\n",
      "Epoch: 189        Loss: 8630.0713  LR: 0.001000000\n",
      "Epoch: 190        Loss: 8628.4707  LR: 0.001000000\n",
      "Epoch: 191        Loss: 8626.8730  LR: 0.001000000\n",
      "Epoch: 192        Loss: 8625.2832  LR: 0.001000000\n",
      "Epoch: 193        Loss: 8623.6914  LR: 0.001000000\n",
      "Epoch: 194        Loss: 8622.1055  LR: 0.001000000\n",
      "Epoch: 195        Loss: 8620.5234  LR: 0.001000000\n",
      "Epoch: 196        Loss: 8618.9473  LR: 0.001000000\n",
      "Epoch: 197        Loss: 8617.3721  LR: 0.001000000\n",
      "Epoch: 198        Loss: 8615.8047  LR: 0.001000000\n",
      "Epoch: 199        Loss: 8614.2373  LR: 0.001000000\n",
      "Epoch: 200        Loss: 8612.6748  LR: 0.001000000\n",
      "Epoch: 201        Loss: 8611.1191  LR: 0.001000000\n",
      "Epoch: 202        Loss: 8609.5635  LR: 0.001000000\n",
      "Epoch: 203        Loss: 8608.0166  LR: 0.001000000\n",
      "Epoch: 204        Loss: 8606.4697  LR: 0.001000000\n",
      "Epoch: 205        Loss: 8604.9268  LR: 0.001000000\n",
      "Epoch: 206        Loss: 8603.3906  LR: 0.001000000\n",
      "Epoch: 207        Loss: 8601.8574  LR: 0.001000000\n",
      "Epoch: 208        Loss: 8600.3271  LR: 0.001000000\n",
      "Epoch: 209        Loss: 8598.7998  LR: 0.001000000\n",
      "Epoch: 210        Loss: 8597.2754  LR: 0.001000000\n",
      "Epoch: 211        Loss: 8595.7539  LR: 0.001000000\n",
      "Epoch: 212        Loss: 8594.2402  LR: 0.001000000\n",
      "Epoch: 213        Loss: 8592.7256  LR: 0.001000000\n",
      "Epoch: 214        Loss: 8591.2168  LR: 0.001000000\n",
      "Epoch: 215        Loss: 8589.7090  LR: 0.001000000\n",
      "Epoch: 216        Loss: 8588.2041  LR: 0.001000000\n",
      "Epoch: 217        Loss: 8586.7041  LR: 0.001000000\n",
      "Epoch: 218        Loss: 8585.2090  LR: 0.001000000\n",
      "Epoch: 219        Loss: 8583.7158  LR: 0.001000000\n",
      "Epoch: 220        Loss: 8582.2285  LR: 0.001000000\n",
      "Epoch: 221        Loss: 8580.7412  LR: 0.001000000\n",
      "Epoch: 222        Loss: 8579.2559  LR: 0.001000000\n",
      "Epoch: 223        Loss: 8577.7773  LR: 0.001000000\n",
      "Epoch: 224        Loss: 8576.3008  LR: 0.001000000\n",
      "Epoch: 225        Loss: 8574.8311  LR: 0.001000000\n",
      "Epoch: 226        Loss: 8573.3613  LR: 0.001000000\n",
      "Epoch: 227        Loss: 8571.8945  LR: 0.001000000\n",
      "Epoch: 228        Loss: 8570.4316  LR: 0.001000000\n",
      "Epoch: 229        Loss: 8568.9736  LR: 0.001000000\n",
      "Epoch: 230        Loss: 8567.5156  LR: 0.001000000\n",
      "Epoch: 231        Loss: 8566.0645  LR: 0.001000000\n",
      "Epoch: 232        Loss: 8564.6152  LR: 0.001000000\n",
      "Epoch: 233        Loss: 8563.1699  LR: 0.001000000\n",
      "Epoch: 234        Loss: 8561.7285  LR: 0.001000000\n",
      "Epoch: 235        Loss: 8560.2900  LR: 0.001000000\n",
      "Epoch: 236        Loss: 8558.8574  LR: 0.001000000\n",
      "Epoch: 237        Loss: 8557.4248  LR: 0.001000000\n",
      "Epoch: 238        Loss: 8555.9951  LR: 0.001000000\n",
      "Epoch: 239        Loss: 8554.5693  LR: 0.001000000\n",
      "Epoch: 240        Loss: 8553.1523  LR: 0.001000000\n",
      "Epoch: 241        Loss: 8551.7324  LR: 0.001000000\n",
      "Epoch: 242        Loss: 8550.3193  LR: 0.001000000\n",
      "Epoch: 243        Loss: 8548.9062  LR: 0.001000000\n",
      "Epoch: 244        Loss: 8547.4980  LR: 0.001000000\n",
      "Epoch: 245        Loss: 8546.0957  LR: 0.001000000\n",
      "Epoch: 246        Loss: 8544.6963  LR: 0.001000000\n",
      "Epoch: 247        Loss: 8543.2998  LR: 0.001000000\n",
      "Epoch: 248        Loss: 8541.9043  LR: 0.001000000\n",
      "Epoch: 249        Loss: 8540.5146  LR: 0.001000000\n",
      "Epoch: 250        Loss: 8539.1230  LR: 0.001000000\n",
      "Epoch: 251        Loss: 8537.7393  LR: 0.001000000\n",
      "Epoch: 252        Loss: 8536.3584  LR: 0.001000000\n",
      "Epoch: 253        Loss: 8534.9814  LR: 0.001000000\n",
      "Epoch: 254        Loss: 8533.6045  LR: 0.001000000\n",
      "Epoch: 255        Loss: 8532.2314  LR: 0.001000000\n",
      "Epoch: 256        Loss: 8530.8613  LR: 0.001000000\n",
      "Epoch: 257        Loss: 8529.4971  LR: 0.001000000\n",
      "Epoch: 258        Loss: 8528.1348  LR: 0.001000000\n",
      "Epoch: 259        Loss: 8526.7744  LR: 0.001000000\n",
      "Epoch: 260        Loss: 8525.4199  LR: 0.001000000\n",
      "Epoch: 261        Loss: 8524.0645  LR: 0.001000000\n",
      "Epoch: 262        Loss: 8522.7139  LR: 0.001000000\n",
      "Epoch: 263        Loss: 8521.3672  LR: 0.001000000\n",
      "Epoch: 264        Loss: 8520.0244  LR: 0.001000000\n",
      "Epoch: 265        Loss: 8518.6826  LR: 0.001000000\n",
      "Epoch: 266        Loss: 8517.3447  LR: 0.001000000\n",
      "Epoch: 267        Loss: 8516.0078  LR: 0.001000000\n",
      "Epoch: 268        Loss: 8514.6797  LR: 0.001000000\n",
      "Epoch: 269        Loss: 8513.3496  LR: 0.001000000\n",
      "Epoch: 270        Loss: 8512.0254  LR: 0.001000000\n",
      "Epoch: 271        Loss: 8510.7041  LR: 0.001000000\n",
      "Epoch: 272        Loss: 8509.3838  LR: 0.001000000\n",
      "Epoch: 273        Loss: 8508.0703  LR: 0.001000000\n",
      "Epoch: 274        Loss: 8506.7607  LR: 0.001000000\n",
      "Epoch: 275        Loss: 8505.4521  LR: 0.001000000\n",
      "Epoch: 276        Loss: 8504.1455  LR: 0.001000000\n",
      "Epoch: 277        Loss: 8502.8418  LR: 0.001000000\n",
      "Epoch: 278        Loss: 8501.5410  LR: 0.001000000\n",
      "Epoch: 279        Loss: 8500.2480  LR: 0.001000000\n",
      "Epoch: 280        Loss: 8498.9561  LR: 0.001000000\n",
      "Epoch: 281        Loss: 8497.6660  LR: 0.001000000\n",
      "Epoch: 282        Loss: 8496.3799  LR: 0.001000000\n",
      "Epoch: 283        Loss: 8495.0957  LR: 0.001000000\n",
      "Epoch: 284        Loss: 8493.8164  LR: 0.001000000\n",
      "Epoch: 285        Loss: 8492.5449  LR: 0.001000000\n",
      "Epoch: 286        Loss: 8491.2725  LR: 0.001000000\n",
      "Epoch: 287        Loss: 8490.0020  LR: 0.001000000\n",
      "Epoch: 288        Loss: 8488.7363  LR: 0.001000000\n",
      "Epoch: 289        Loss: 8487.4727  LR: 0.001000000\n",
      "Epoch: 290        Loss: 8486.2148  LR: 0.001000000\n",
      "Epoch: 291        Loss: 8484.9609  LR: 0.001000000\n",
      "Epoch: 292        Loss: 8483.7070  LR: 0.001000000\n",
      "Epoch: 293        Loss: 8482.4590  LR: 0.001000000\n",
      "Epoch: 294        Loss: 8481.2129  LR: 0.001000000\n",
      "Epoch: 295        Loss: 8479.9717  LR: 0.001000000\n",
      "Epoch: 296        Loss: 8478.7383  LR: 0.001000000\n",
      "Epoch: 297        Loss: 8477.5049  LR: 0.001000000\n",
      "Epoch: 298        Loss: 8476.2744  LR: 0.001000000\n",
      "Epoch: 299        Loss: 8475.0469  LR: 0.001000000\n",
      "Epoch: 300        Loss: 8473.8242  LR: 0.001000000\n",
      "Epoch: 301        Loss: 8472.6055  LR: 0.001000000\n",
      "Epoch: 302        Loss: 8471.3916  LR: 0.001000000\n",
      "Epoch: 303        Loss: 8470.1797  LR: 0.001000000\n",
      "Epoch: 304        Loss: 8468.9727  LR: 0.001000000\n",
      "Epoch: 305        Loss: 8467.7676  LR: 0.001000000\n",
      "Epoch: 306        Loss: 8466.5674  LR: 0.001000000\n",
      "Epoch: 307        Loss: 8465.3789  LR: 0.001000000\n",
      "Epoch: 308        Loss: 8464.1875  LR: 0.001000000\n",
      "Epoch: 309        Loss: 8462.9990  LR: 0.001000000\n",
      "Epoch: 310        Loss: 8461.8145  LR: 0.001000000\n",
      "Epoch: 311        Loss: 8460.6367  LR: 0.001000000\n",
      "Epoch: 312        Loss: 8459.4609  LR: 0.001000000\n",
      "Epoch: 313        Loss: 8458.2939  LR: 0.001000000\n",
      "Epoch: 314        Loss: 8457.1270  LR: 0.001000000\n",
      "Epoch: 315        Loss: 8455.9668  LR: 0.001000000\n",
      "Epoch: 316        Loss: 8454.8145  LR: 0.001000000\n",
      "Epoch: 317        Loss: 8453.6602  LR: 0.001000000\n",
      "Epoch: 318        Loss: 8452.5137  LR: 0.001000000\n",
      "Epoch: 319        Loss: 8451.3701  LR: 0.001000000\n",
      "Epoch: 320        Loss: 8450.2227  LR: 0.001000000\n",
      "Epoch: 321        Loss: 8449.0820  LR: 0.001000000\n",
      "Epoch: 322        Loss: 8447.9434  LR: 0.001000000\n",
      "Epoch: 323        Loss: 8446.8115  LR: 0.001000000\n",
      "Epoch: 324        Loss: 8445.6865  LR: 0.001000000\n",
      "Epoch: 325        Loss: 8444.5576  LR: 0.001000000\n",
      "Epoch: 326        Loss: 8443.4336  LR: 0.001000000\n",
      "Epoch: 327        Loss: 8442.3154  LR: 0.001000000\n",
      "Epoch: 328        Loss: 8441.1982  LR: 0.001000000\n",
      "Epoch: 329        Loss: 8440.0869  LR: 0.001000000\n",
      "Epoch: 330        Loss: 8438.9805  LR: 0.001000000\n",
      "Epoch: 331        Loss: 8437.8721  LR: 0.001000000\n",
      "Epoch: 332        Loss: 8436.7715  LR: 0.001000000\n",
      "Epoch: 333        Loss: 8435.6719  LR: 0.001000000\n",
      "Epoch: 334        Loss: 8434.5859  LR: 0.001000000\n",
      "Epoch: 335        Loss: 8433.4971  LR: 0.001000000\n",
      "Epoch: 336        Loss: 8432.4092  LR: 0.001000000\n",
      "Epoch: 337        Loss: 8431.3252  LR: 0.001000000\n",
      "Epoch: 338        Loss: 8430.2451  LR: 0.001000000\n",
      "Epoch: 339        Loss: 8429.1699  LR: 0.001000000\n",
      "Epoch: 340        Loss: 8428.0986  LR: 0.001000000\n",
      "Epoch: 341        Loss: 8427.0303  LR: 0.001000000\n",
      "Epoch: 342        Loss: 8425.9619  LR: 0.001000000\n",
      "Epoch: 343        Loss: 8424.8984  LR: 0.001000000\n",
      "Epoch: 344        Loss: 8423.8389  LR: 0.001000000\n",
      "Epoch: 345        Loss: 8422.7822  LR: 0.001000000\n",
      "Epoch: 346        Loss: 8421.7305  LR: 0.001000000\n",
      "Epoch: 347        Loss: 8420.6914  LR: 0.001000000\n",
      "Epoch: 348        Loss: 8419.6426  LR: 0.001000000\n",
      "Epoch: 349        Loss: 8418.5957  LR: 0.001000000\n",
      "Epoch: 350        Loss: 8417.5547  LR: 0.001000000\n",
      "Epoch: 351        Loss: 8416.5166  LR: 0.001000000\n",
      "Epoch: 352        Loss: 8415.4824  LR: 0.001000000\n",
      "Epoch: 353        Loss: 8414.4492  LR: 0.001000000\n",
      "Epoch: 354        Loss: 8413.4209  LR: 0.001000000\n",
      "Epoch: 355        Loss: 8412.3955  LR: 0.001000000\n",
      "Epoch: 356        Loss: 8411.3750  LR: 0.001000000\n",
      "Epoch: 357        Loss: 8410.3564  LR: 0.001000000\n",
      "Epoch: 358        Loss: 8409.3447  LR: 0.001000000\n",
      "Epoch: 359        Loss: 8408.3320  LR: 0.001000000\n",
      "Epoch: 360        Loss: 8407.3223  LR: 0.001000000\n",
      "Epoch: 361        Loss: 8406.3184  LR: 0.001000000\n",
      "Epoch: 362        Loss: 8405.3184  LR: 0.001000000\n",
      "Epoch: 363        Loss: 8404.3203  LR: 0.001000000\n",
      "Epoch: 364        Loss: 8403.3262  LR: 0.001000000\n",
      "Epoch: 365        Loss: 8402.3457  LR: 0.001000000\n",
      "Epoch: 366        Loss: 8401.3574  LR: 0.001000000\n",
      "Epoch: 367        Loss: 8400.3730  LR: 0.001000000\n",
      "Epoch: 368        Loss: 8399.3926  LR: 0.001000000\n",
      "Epoch: 369        Loss: 8398.4170  LR: 0.001000000\n",
      "Epoch: 370        Loss: 8397.4414  LR: 0.001000000\n",
      "Epoch: 371        Loss: 8396.4727  LR: 0.001000000\n",
      "Epoch: 372        Loss: 8395.5068  LR: 0.001000000\n",
      "Epoch: 373        Loss: 8394.5439  LR: 0.001000000\n",
      "Epoch: 374        Loss: 8393.5859  LR: 0.001000000\n",
      "Epoch: 375        Loss: 8392.6309  LR: 0.001000000\n",
      "Epoch: 376        Loss: 8391.6787  LR: 0.001000000\n",
      "Epoch: 377        Loss: 8390.7314  LR: 0.001000000\n",
      "Epoch: 378        Loss: 8389.7900  LR: 0.001000000\n",
      "Epoch: 379        Loss: 8388.8506  LR: 0.001000000\n",
      "Epoch: 380        Loss: 8387.9453  LR: 0.001000000\n",
      "Epoch: 381        Loss: 8387.0117  LR: 0.001000000\n",
      "Epoch: 382        Loss: 8386.0820  LR: 0.001000000\n",
      "Epoch: 383        Loss: 8385.1719  LR: 0.001000000\n",
      "Epoch: 384        Loss: 8384.2510  LR: 0.001000000\n",
      "Epoch: 385        Loss: 8383.3320  LR: 0.001000000\n",
      "Epoch: 386        Loss: 8382.4180  LR: 0.001000000\n",
      "Epoch: 387        Loss: 8381.5068  LR: 0.001000000\n",
      "Epoch: 388        Loss: 8380.6025  LR: 0.001000000\n",
      "Epoch: 389        Loss: 8379.7021  LR: 0.001000000\n",
      "Epoch: 390        Loss: 8378.8076  LR: 0.001000000\n",
      "Epoch: 391        Loss: 8377.9141  LR: 0.001000000\n",
      "Epoch: 392        Loss: 8377.0293  LR: 0.001000000\n",
      "Epoch: 393        Loss: 8376.1455  LR: 0.001000000\n",
      "Epoch: 394        Loss: 8375.2715  LR: 0.001000000\n",
      "Epoch: 395        Loss: 8374.3994  LR: 0.001000000\n",
      "Epoch: 396        Loss: 8373.5322  LR: 0.001000000\n",
      "Epoch: 397        Loss: 8372.6738  LR: 0.001000000\n",
      "Epoch: 398        Loss: 8371.8340  LR: 0.001000000\n",
      "Epoch: 399        Loss: 8370.9805  LR: 0.001000000\n",
      "Epoch: 400        Loss: 8370.1299  LR: 0.001000000\n",
      "Epoch: 401        Loss: 8369.2861  LR: 0.001000000\n",
      "Epoch: 402        Loss: 8368.4434  LR: 0.001000000\n",
      "Epoch: 403        Loss: 8367.6123  LR: 0.001000000\n",
      "Epoch: 404        Loss: 8366.7812  LR: 0.001000000\n",
      "Epoch: 405        Loss: 8365.9609  LR: 0.001000000\n",
      "Epoch: 406        Loss: 8365.1416  LR: 0.001000000\n",
      "Epoch: 407        Loss: 8364.3350  LR: 0.001000000\n",
      "Epoch: 408        Loss: 8363.5293  LR: 0.001000000\n",
      "Epoch: 409        Loss: 8362.7305  LR: 0.001000000\n",
      "Epoch: 410        Loss: 8361.9346  LR: 0.001000000\n",
      "Epoch: 411        Loss: 8361.1494  LR: 0.001000000\n",
      "Epoch: 412        Loss: 8360.3691  LR: 0.001000000\n",
      "Epoch: 413        Loss: 8359.6211  LR: 0.001000000\n",
      "Epoch: 414        Loss: 8358.8506  LR: 0.001000000\n",
      "Epoch: 415        Loss: 8358.0859  LR: 0.001000000\n",
      "Epoch: 416        Loss: 8357.3350  LR: 0.001000000\n",
      "Epoch: 417        Loss: 8356.5830  LR: 0.001000000\n",
      "Epoch: 418        Loss: 8355.8389  LR: 0.001000000\n",
      "Epoch: 419        Loss: 8355.1035  LR: 0.001000000\n",
      "Epoch: 420        Loss: 8354.3662  LR: 0.001000000\n",
      "Epoch: 421        Loss: 8353.6367  LR: 0.001000000\n",
      "Epoch: 422        Loss: 8352.9170  LR: 0.001000000\n",
      "Epoch: 423        Loss: 8352.2012  LR: 0.001000000\n",
      "Epoch: 424        Loss: 8351.4805  LR: 0.001000000\n",
      "Epoch: 425        Loss: 8350.7695  LR: 0.001000000\n",
      "Epoch: 426        Loss: 8350.0801  LR: 0.001000000\n",
      "Epoch: 427        Loss: 8349.3779  LR: 0.001000000\n",
      "Epoch: 428        Loss: 8348.6826  LR: 0.001000000\n",
      "Epoch: 429        Loss: 8347.9883  LR: 0.001000000\n",
      "Epoch: 430        Loss: 8347.3008  LR: 0.001000000\n",
      "Epoch: 431        Loss: 8346.6191  LR: 0.001000000\n",
      "Epoch: 432        Loss: 8345.9453  LR: 0.001000000\n",
      "Epoch: 433        Loss: 8345.2812  LR: 0.001000000\n",
      "Epoch: 434        Loss: 8344.6113  LR: 0.001000000\n",
      "Epoch: 435        Loss: 8343.9463  LR: 0.001000000\n",
      "Epoch: 436        Loss: 8343.3340  LR: 0.001000000\n",
      "Epoch: 437        Loss: 8342.6797  LR: 0.001000000\n",
      "Epoch: 438        Loss: 8342.0332  LR: 0.001000000\n",
      "Epoch: 439        Loss: 8341.3867  LR: 0.001000000\n",
      "Epoch: 440        Loss: 8340.7529  LR: 0.001000000\n",
      "Epoch: 441        Loss: 8340.1201  LR: 0.001000000\n",
      "Epoch: 442        Loss: 8339.4961  LR: 0.001000000\n",
      "Epoch: 443        Loss: 8338.8721  LR: 0.001000000\n",
      "Epoch: 444        Loss: 8338.2559  LR: 0.001000000\n",
      "Epoch: 445        Loss: 8337.6572  LR: 0.001000000\n",
      "Epoch: 446        Loss: 8337.0508  LR: 0.001000000\n",
      "Epoch: 447        Loss: 8336.4541  LR: 0.001000000\n",
      "Epoch: 448        Loss: 8335.8574  LR: 0.001000000\n",
      "Epoch: 449        Loss: 8335.2715  LR: 0.001000000\n",
      "Epoch: 450        Loss: 8334.6914  LR: 0.001000000\n",
      "Epoch: 451        Loss: 8334.1230  LR: 0.001000000\n",
      "Epoch: 452        Loss: 8333.5547  LR: 0.001000000\n",
      "Epoch: 453        Loss: 8333.0078  LR: 0.001000000\n",
      "Epoch: 454        Loss: 8332.4521  LR: 0.001000000\n",
      "Epoch: 455        Loss: 8331.9131  LR: 0.001000000\n",
      "Epoch: 456        Loss: 8331.3682  LR: 0.001000000\n",
      "Epoch: 457        Loss: 8330.8330  LR: 0.001000000\n",
      "Epoch: 458        Loss: 8330.3057  LR: 0.001000000\n",
      "Epoch: 459        Loss: 8329.7842  LR: 0.001000000\n",
      "Epoch: 460        Loss: 8329.2705  LR: 0.001000000\n",
      "Epoch: 461        Loss: 8328.7588  LR: 0.001000000\n",
      "Epoch: 462        Loss: 8328.2598  LR: 0.001000000\n",
      "Epoch: 463        Loss: 8327.7793  LR: 0.001000000\n",
      "Epoch: 464        Loss: 8327.2783  LR: 0.001000000\n",
      "Epoch: 465        Loss: 8326.7842  LR: 0.001000000\n",
      "Epoch: 466        Loss: 8326.2910  LR: 0.001000000\n",
      "Epoch: 467        Loss: 8325.8828  LR: 0.001000000\n",
      "Epoch: 468        Loss: 8325.4023  LR: 0.001000000\n",
      "Epoch: 469        Loss: 8324.9189  LR: 0.001000000\n",
      "Epoch: 470        Loss: 8324.4453  LR: 0.001000000\n",
      "Epoch: 471        Loss: 8323.9785  LR: 0.001000000\n",
      "Epoch: 472        Loss: 8323.5127  LR: 0.001000000\n",
      "Epoch: 473        Loss: 8323.0557  LR: 0.001000000\n",
      "Epoch: 474        Loss: 8322.6055  LR: 0.001000000\n",
      "Epoch: 475        Loss: 8322.1562  LR: 0.001000000\n",
      "Epoch: 476        Loss: 8321.7266  LR: 0.001000000\n",
      "Epoch: 477        Loss: 8321.2881  LR: 0.001000000\n",
      "Epoch: 478        Loss: 8320.8594  LR: 0.001000000\n",
      "Epoch: 479        Loss: 8320.4326  LR: 0.001000000\n",
      "Epoch: 480        Loss: 8320.0117  LR: 0.001000000\n",
      "Epoch: 481        Loss: 8319.5996  LR: 0.001000000\n",
      "Epoch: 482        Loss: 8319.2031  LR: 0.001000000\n",
      "Epoch: 483        Loss: 8318.7988  LR: 0.001000000\n",
      "Epoch: 484        Loss: 8318.4268  LR: 0.001000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 485        Loss: 8318.0342  LR: 0.001000000\n",
      "Epoch: 486        Loss: 8317.6426  LR: 0.001000000\n",
      "Epoch: 487        Loss: 8317.2588  LR: 0.001000000\n",
      "Epoch: 488        Loss: 8316.8838  LR: 0.001000000\n",
      "Epoch: 489        Loss: 8316.5127  LR: 0.001000000\n",
      "Epoch: 490        Loss: 8316.1543  LR: 0.001000000\n",
      "Epoch: 491        Loss: 8315.7939  LR: 0.001000000\n",
      "Epoch: 492        Loss: 8315.4434  LR: 0.001000000\n",
      "Epoch: 493        Loss: 8315.1035  LR: 0.001000000\n",
      "Epoch: 494        Loss: 8314.7656  LR: 0.001000000\n",
      "Epoch: 495        Loss: 8314.4375  LR: 0.001000000\n",
      "Epoch: 496        Loss: 8314.1191  LR: 0.001000000\n",
      "Epoch: 497        Loss: 8313.8174  LR: 0.001000000\n",
      "Epoch: 498        Loss: 8313.5430  LR: 0.001000000\n",
      "Epoch: 499        Loss: 8313.2373  LR: 0.001000000\n",
      "Epoch: 500        Loss: 8312.9395  LR: 0.001000000\n",
      "Epoch: 501        Loss: 8312.6465  LR: 0.001000000\n",
      "Epoch: 502        Loss: 8312.3643  LR: 0.001000000\n",
      "Epoch: 503        Loss: 8312.0879  LR: 0.001000000\n",
      "Epoch: 504        Loss: 8311.8193  LR: 0.001000000\n",
      "Epoch: 505        Loss: 8311.5635  LR: 0.001000000\n",
      "Epoch: 506        Loss: 8311.3096  LR: 0.001000000\n",
      "Epoch: 507        Loss: 8311.0693  LR: 0.001000000\n",
      "Epoch: 508        Loss: 8310.8379  LR: 0.001000000\n",
      "Epoch: 509        Loss: 8310.7637  LR: 0.001000000\n",
      "Epoch: 510        Loss: 8310.6113  LR: 0.001000000\n",
      "Epoch: 511        Loss: 8310.5391  LR: 0.001000000\n",
      "Epoch: 512        Loss: 8310.4121  LR: 0.001000000\n",
      "Epoch: 513        Loss: 8310.3408  LR: 0.001000000\n",
      "Epoch: 514        Loss: 8310.2021  LR: 0.001000000\n",
      "Epoch: 515        Lr was reduced to: 0.000700000\n",
      "Epoch: 516        Loss: 8310.1758  LR: 0.000700000\n",
      "Epoch: 517        Loss: 8310.0449  LR: 0.000700000\n",
      "Epoch: 518        Loss: 8309.8965  LR: 0.000700000\n",
      "Epoch: 519        Loss: 8309.7520  LR: 0.000700000\n",
      "Epoch: 520        Loss: 8309.6211  LR: 0.000700000\n",
      "Epoch: 521        Loss: 8309.5312  LR: 0.000700000\n",
      "Epoch: 522        Loss: 8309.4697  LR: 0.000700000\n",
      "Epoch: 523        Loss: 8309.3984  LR: 0.000700000\n",
      "Epoch: 524        Loss: 8309.3389  LR: 0.000700000\n",
      "Epoch: 525        Loss: 8309.2598  LR: 0.000700000\n",
      "Epoch: 526        Loss: 8309.2021  LR: 0.000700000\n",
      "Epoch: 527        Loss: 8309.1260  LR: 0.000700000\n",
      "Epoch: 528        Loss: 8309.0674  LR: 0.000700000\n",
      "Epoch: 529        Loss: 8308.9941  LR: 0.000700000\n",
      "Epoch: 530        Loss: 8308.9365  LR: 0.000700000\n",
      "Epoch: 531        Loss: 8308.8652  LR: 0.000700000\n",
      "Epoch: 532        Loss: 8308.8076  LR: 0.000700000\n",
      "Epoch: 533        Loss: 8308.7373  LR: 0.000700000\n",
      "Epoch: 534        Loss: 8308.6807  LR: 0.000700000\n",
      "Epoch: 535        Loss: 8308.6123  LR: 0.000700000\n",
      "Epoch: 536        Loss: 8308.5547  LR: 0.000700000\n",
      "Epoch: 537        Loss: 8308.4922  LR: 0.000700000\n",
      "Epoch: 538        Loss: 8308.4355  LR: 0.000700000\n",
      "Epoch: 539        Loss: 8308.3701  LR: 0.000700000\n",
      "Epoch: 540        Loss: 8308.3145  LR: 0.000700000\n",
      "Epoch: 541        Loss: 8308.2520  LR: 0.000700000\n",
      "Epoch: 542        Loss: 8308.1963  LR: 0.000700000\n",
      "Epoch: 543        Loss: 8308.1377  LR: 0.000700000\n",
      "Epoch: 544        Loss: 8308.0820  LR: 0.000700000\n",
      "Epoch: 545        Loss: 8308.0254  LR: 0.000700000\n",
      "Epoch: 546        Loss: 8307.9717  LR: 0.000700000\n",
      "Epoch: 547        Loss: 8307.9150  LR: 0.000700000\n",
      "Epoch: 548        Loss: 8307.8604  LR: 0.000700000\n",
      "Epoch: 549        Loss: 8307.8086  LR: 0.000700000\n",
      "Epoch: 550        Loss: 8307.7539  LR: 0.000700000\n",
      "Epoch: 551        Loss: 8307.7012  LR: 0.000700000\n",
      "Epoch: 552        Loss: 8307.6465  LR: 0.000700000\n",
      "Epoch: 553        Loss: 8307.5977  LR: 0.000700000\n",
      "Epoch: 554        Loss: 8307.5430  LR: 0.000700000\n",
      "Epoch: 555        Loss: 8307.4961  LR: 0.000700000\n",
      "Epoch: 556        Loss: 8307.4434  LR: 0.000700000\n",
      "Epoch: 557        Loss: 8307.3994  LR: 0.000700000\n",
      "Epoch: 558        Loss: 8307.3438  LR: 0.000700000\n",
      "Epoch: 559        Loss: 8307.3281  LR: 0.000700000\n",
      "Epoch: 560        Lr was reduced to: 0.000490000\n",
      "Epoch: 561        Loss: 8307.3086  LR: 0.000490000\n",
      "Epoch: 562        Lr was reduced to: 0.000343000\n",
      "Epoch: 563        Loss: 8307.2471  LR: 0.000343000\n",
      "Epoch: 564        Loss: 8307.2002  LR: 0.000343000\n",
      "Epoch: 565        Loss: 8307.1543  LR: 0.000343000\n",
      "Epoch: 566        Loss: 8307.1094  LR: 0.000343000\n",
      "Epoch: 567        Loss: 8307.0635  LR: 0.000343000\n",
      "Epoch: 568        Loss: 8307.0186  LR: 0.000343000\n",
      "Epoch: 569        Loss: 8306.9746  LR: 0.000343000\n",
      "Epoch: 570        Loss: 8306.9512  LR: 0.000343000\n",
      "Epoch: 571        Loss: 8306.9316  LR: 0.000343000\n",
      "Epoch: 572        Loss: 8306.9092  LR: 0.000343000\n",
      "Epoch: 573        Loss: 8306.8887  LR: 0.000343000\n",
      "Epoch: 574        Loss: 8306.8652  LR: 0.000343000\n",
      "Epoch: 575        Loss: 8306.8477  LR: 0.000343000\n",
      "Epoch: 576        Loss: 8306.8232  LR: 0.000343000\n",
      "Epoch: 577        Loss: 8306.8047  LR: 0.000343000\n",
      "Epoch: 578        Loss: 8306.7822  LR: 0.000343000\n",
      "Epoch: 579        Loss: 8306.7637  LR: 0.000343000\n",
      "Epoch: 580        Loss: 8306.7402  LR: 0.000343000\n",
      "Epoch: 581        Loss: 8306.7227  LR: 0.000343000\n",
      "Epoch: 582        Loss: 8306.6992  LR: 0.000343000\n",
      "Epoch: 583        Loss: 8306.6836  LR: 0.000343000\n",
      "Epoch: 584        Loss: 8306.6602  LR: 0.000343000\n",
      "Epoch: 585        Loss: 8306.6436  LR: 0.000343000\n",
      "Epoch: 586        Loss: 8306.6211  LR: 0.000343000\n",
      "Epoch: 587        Loss: 8306.6045  LR: 0.000343000\n",
      "Epoch: 588        Loss: 8306.5820  LR: 0.000343000\n",
      "Epoch: 589        Loss: 8306.5674  LR: 0.000343000\n",
      "Epoch: 590        Loss: 8306.5449  LR: 0.000343000\n",
      "Epoch: 591        Loss: 8306.5293  LR: 0.000343000\n",
      "Epoch: 592        Loss: 8306.5068  LR: 0.000343000\n",
      "Epoch: 593        Loss: 8306.4932  LR: 0.000343000\n",
      "Epoch: 594        Loss: 8306.4707  LR: 0.000343000\n",
      "Epoch: 595        Loss: 8306.4570  LR: 0.000343000\n",
      "Epoch: 596        Loss: 8306.4346  LR: 0.000343000\n",
      "Epoch: 597        Loss: 8306.4209  LR: 0.000343000\n",
      "Epoch: 598        Loss: 8306.3994  LR: 0.000343000\n",
      "Epoch: 599        Loss: 8306.3857  LR: 0.000343000\n",
      "Epoch: 600        Loss: 8306.3643  LR: 0.000343000\n",
      "Epoch: 601        Loss: 8306.3516  LR: 0.000343000\n",
      "Epoch: 602        Loss: 8306.3291  LR: 0.000343000\n",
      "Epoch: 603        Loss: 8306.3174  LR: 0.000343000\n",
      "Epoch: 604        Loss: 8306.2949  LR: 0.000343000\n",
      "Epoch: 605        Loss: 8306.2861  LR: 0.000343000\n",
      "Epoch: 606        Loss: 8306.2656  LR: 0.000343000\n",
      "Epoch: 607        Loss: 8306.2529  LR: 0.000343000\n",
      "Epoch: 608        Loss: 8306.2324  LR: 0.000343000\n",
      "Epoch: 609        Loss: 8306.2217  LR: 0.000343000\n",
      "Epoch: 610        Loss: 8306.2012  LR: 0.000343000\n",
      "Epoch: 611        Loss: 8306.1895  LR: 0.000343000\n",
      "Epoch: 612        Loss: 8306.1670  LR: 0.000343000\n",
      "Epoch: 613        Loss: 8306.1602  LR: 0.000343000\n",
      "Epoch: 614        Loss: 8306.1387  LR: 0.000343000\n",
      "Epoch: 615        Loss: 8306.1299  LR: 0.000343000\n",
      "Epoch: 616        Loss: 8306.1094  LR: 0.000343000\n",
      "Epoch: 617        Loss: 8306.0996  LR: 0.000343000\n",
      "Epoch: 618        Loss: 8306.0781  LR: 0.000343000\n",
      "Epoch: 619        Loss: 8306.0684  LR: 0.000343000\n",
      "Epoch: 620        Loss: 8306.0488  LR: 0.000343000\n",
      "Epoch: 621        Loss: 8306.0410  LR: 0.000343000\n",
      "Epoch: 622        Loss: 8306.0215  LR: 0.000343000\n",
      "Epoch: 623        Loss: 8306.0127  LR: 0.000343000\n",
      "Epoch: 624        Loss: 8305.9922  LR: 0.000343000\n",
      "Epoch: 625        Loss: 8305.9844  LR: 0.000343000\n",
      "Epoch: 626        Loss: 8305.9629  LR: 0.000343000\n",
      "Epoch: 627        Loss: 8305.9570  LR: 0.000343000\n",
      "Epoch: 628        Loss: 8305.9365  LR: 0.000343000\n",
      "Epoch: 629        Loss: 8305.9316  LR: 0.000343000\n",
      "Epoch: 630        Loss: 8305.9111  LR: 0.000343000\n",
      "Epoch: 631        Loss: 8305.9053  LR: 0.000343000\n",
      "Epoch: 632        Loss: 8305.8848  LR: 0.000343000\n",
      "Epoch: 633        Loss: 8305.8809  LR: 0.000343000\n",
      "Epoch: 634        Loss: 8305.8604  LR: 0.000343000\n",
      "Epoch: 635        Loss: 8305.8555  LR: 0.000343000\n",
      "Epoch: 636        Loss: 8305.8359  LR: 0.000343000\n",
      "Epoch: 637        Loss: 8305.8320  LR: 0.000343000\n",
      "Epoch: 638        Loss: 8305.8125  LR: 0.000343000\n",
      "Epoch: 639        Loss: 8305.8096  LR: 0.000343000\n",
      "Epoch: 640        Loss: 8305.7891  LR: 0.000343000\n",
      "Epoch: 641        Loss did not change\n",
      "Epoch: 642        Loss: 8305.7695  LR: 0.000343000\n",
      "Epoch: 643        Loss: 8305.7666  LR: 0.000343000\n",
      "Epoch: 644        Loss: 8305.7461  LR: 0.000343000\n",
      "Epoch: 645        Loss: 8305.7441  LR: 0.000343000\n",
      "Epoch: 646        Loss: 8305.7246  LR: 0.000343000\n",
      "Epoch: 647        Loss: 8305.7236  LR: 0.000343000\n",
      "Epoch: 648        Loss: 8305.7051  LR: 0.000343000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 649        Loss: 8305.7031  LR: 0.000343000\n",
      "Epoch: 650        Loss: 8305.6836  LR: 0.000343000\n",
      "Epoch: 651        Loss did not change\n",
      "Epoch: 652        Loss: 8305.6650  LR: 0.000343000\n",
      "Epoch: 653        Loss did not change\n",
      "Epoch: 654        Loss: 8305.6455  LR: 0.000343000\n",
      "Epoch: 655        Lr was reduced to: 0.000240100\n",
      "Epoch: 656        Loss: 8305.6270  LR: 0.000240100\n",
      "Epoch: 657        Loss: 8305.6162  LR: 0.000240100\n",
      "Epoch: 658        Loss: 8305.6035  LR: 0.000240100\n",
      "Epoch: 659        Loss: 8305.5918  LR: 0.000240100\n",
      "Epoch: 660        Loss: 8305.5811  LR: 0.000240100\n",
      "Epoch: 661        Loss: 8305.5684  LR: 0.000240100\n",
      "Epoch: 662        Loss: 8305.5586  LR: 0.000240100\n",
      "Epoch: 663        Loss: 8305.5488  LR: 0.000240100\n",
      "Epoch: 664        Loss: 8305.5391  LR: 0.000240100\n",
      "Epoch: 665        Loss: 8305.5303  LR: 0.000240100\n",
      "Epoch: 666        Loss: 8305.5215  LR: 0.000240100\n",
      "Epoch: 667        Loss: 8305.5117  LR: 0.000240100\n",
      "Epoch: 668        Loss: 8305.5020  LR: 0.000240100\n",
      "Epoch: 669        Loss: 8305.4941  LR: 0.000240100\n",
      "Epoch: 670        Loss: 8305.4863  LR: 0.000240100\n",
      "Epoch: 671        Loss: 8305.4775  LR: 0.000240100\n",
      "Epoch: 672        Loss: 8305.4707  LR: 0.000240100\n",
      "Epoch: 673        Loss: 8305.4639  LR: 0.000240100\n",
      "Epoch: 674        Lr was reduced to: 0.000168070\n",
      "Epoch: 675        Loss: 8305.4590  LR: 0.000168070\n",
      "Epoch: 676        Lr was reduced to: 0.000117649\n",
      "Epoch: 677        Loss: 8305.4580  LR: 0.000117649\n",
      "Epoch: 678        Loss: 8305.4541  LR: 0.000117649\n",
      "Epoch: 679        Loss: 8305.4512  LR: 0.000117649\n",
      "Epoch: 680        Loss: 8305.4482  LR: 0.000117649\n",
      "Epoch: 681        Loss: 8305.4463  LR: 0.000117649\n",
      "Epoch: 682        Loss: 8305.4424  LR: 0.000117649\n",
      "Epoch: 683        Loss: 8305.4404  LR: 0.000117649\n",
      "Epoch: 684        Loss: 8305.4375  LR: 0.000117649\n",
      "Epoch: 685        Loss: 8305.4355  LR: 0.000117649\n",
      "Epoch: 686        Loss: 8305.4326  LR: 0.000117649\n",
      "Epoch: 687        Loss: 8305.4297  LR: 0.000117649\n",
      "Epoch: 688        Loss: 8305.4268  LR: 0.000117649\n",
      "Epoch: 689        Loss: 8305.4238  LR: 0.000117649\n",
      "Epoch: 690        Loss: 8305.4219  LR: 0.000117649\n",
      "Epoch: 691        Loss: 8305.4199  LR: 0.000117649\n",
      "Epoch: 692        Loss: 8305.4189  LR: 0.000117649\n",
      "Epoch: 693        Loss did not change\n",
      "Epoch: 694        Loss: 8305.4160  LR: 0.000117649\n",
      "Epoch: 695        Loss did not change\n",
      "Epoch: 696        Loss: 8305.4141  LR: 0.000117649\n",
      "Epoch: 697        Lr was reduced to: 0.000082354\n",
      "Epoch: 698        Loss: 8305.4121  LR: 0.000082354\n",
      "Epoch: 699        Loss: 8305.4111  LR: 0.000082354\n",
      "Epoch: 700        Loss: 8305.4102  LR: 0.000082354\n",
      "Epoch: 701        Loss: 8305.4092  LR: 0.000082354\n",
      "Epoch: 702        Loss: 8305.4082  LR: 0.000082354\n",
      "Epoch: 703        Loss: 8305.4062  LR: 0.000082354\n",
      "Epoch: 704        Loss: 8305.4053  LR: 0.000082354\n",
      "Epoch: 705        Loss: 8305.4043  LR: 0.000082354\n",
      "Epoch: 706        Loss: 8305.4033  LR: 0.000082354\n",
      "Epoch: 707        Loss: 8305.4023  LR: 0.000082354\n",
      "Epoch: 708        Lr was reduced to: 0.000057648\n",
      "Epoch: 709        Loss: 8305.4014  LR: 0.000057648\n",
      "Epoch: 710        Lr was reduced to: 0.000040354\n",
      "Epoch: 711        Loss: 8305.4014  LR: 0.000040354\n",
      "Epoch: 712        Loss did not change\n",
      "Epoch: 713        Loss: 8305.3994  LR: 0.000040354\n",
      "Epoch: 714        Lr was reduced to: 0.000028248\n",
      "Epoch: 715        Loss: 8305.3994  LR: 0.000028248\n",
      "Epoch: 716        Loss did not change\n",
      "Epoch: 717        Loss: 8305.3984  LR: 0.000028248\n",
      "Epoch: 718        Loss did not change\n",
      "Epoch: 719        Loss did not change\n",
      "Epoch: 720        Loss: 8305.3975  LR: 0.000028248\n",
      "Epoch: 721        Loss did not change\n",
      "Epoch: 722        Loss did not change\n",
      "Epoch: 723        Loss did not change\n",
      "Epoch: 724        Loss did not change\n",
      "Epoch: 725        Loss did not change\n",
      "Epoch: 726        Loss did not change\n",
      "Epoch: 727        Loss: 8305.3965  LR: 0.000028248\n",
      "Epoch: 728        Loss did not change\n",
      "Epoch: 729        Loss did not change\n",
      "Epoch: 730        Loss: 8305.3955  LR: 0.000028248\n",
      "Epoch: 731        Loss did not change\n",
      "Epoch: 732        Lr was reduced to: 0.000019773\n",
      "Epoch: 733        Loss: 8305.3955  LR: 0.000019773\n",
      "Epoch: 734        Loss did not change\n",
      "Epoch: 735        Loss: 8305.3945  LR: 0.000019773\n",
      "Epoch: 736        Loss did not change\n",
      "Epoch: 737        Loss did not change\n",
      "Epoch: 738        Loss did not change\n",
      "Epoch: 739        Loss did not change\n",
      "Epoch: 740        Loss did not change\n",
      "Epoch: 741        Loss: 8305.3926  LR: 0.000019773\n",
      "Epoch: 742        Lr was reduced to: 0.000013841\n",
      "Epoch: 743        Loss: 8305.3936  LR: 0.000013841\n",
      "Epoch: 744        Loss: 8305.3926  LR: 0.000013841\n",
      "Epoch: 745        Loss did not change\n",
      "Epoch: 746        Lr was reduced to: 0.000009689\n",
      "Epoch: 747        Loss did not change\n",
      "Epoch: 748        Loss: 8305.3926  LR: 0.000009689\n",
      "Epoch: 749        Lr was reduced to: 0.000006782\n",
      "Epoch: 750        Loss did not change\n",
      "Epoch: 751        Loss: 8305.3926  LR: 0.000006782\n",
      "Epoch: 752        Loss did not change\n",
      "Epoch: 753        Loss did not change\n",
      "Epoch: 754        Loss did not change\n",
      "Epoch: 755        Loss did not change\n",
      "Epoch: 756        Loss did not change\n",
      "Epoch: 757        Loss did not change\n",
      "Epoch: 758        Loss did not change\n",
      "Epoch: 759        Loss did not change\n",
      "Epoch: 760        Loss: 8305.3916  LR: 0.000006782\n",
      "Epoch: 761        Lr was reduced to: 0.000004748\n",
      "Epoch: 762        Loss did not change\n",
      "Epoch: 763        Loss did not change\n",
      "Epoch: 764        Loss: 8305.3916  LR: 0.000004748\n",
      "Epoch: 765        Loss did not change\n",
      "Epoch: 766        Loss did not change\n",
      "Epoch: 767        Lr was reduced to: 0.000003323\n",
      "Epoch: 768        Loss: 8305.3916  LR: 0.000003323\n",
      "Epoch: 769        Lr was reduced to: 0.000002326\n",
      "Epoch: 770        Loss: 8305.3916  LR: 0.000002326\n",
      "Epoch: 771        Loss did not change\n",
      "Epoch: 772        Lr was reduced to: 0.000001628\n",
      "Epoch: 773        Loss did not change\n",
      "Epoch: 774        Loss: 8305.3916  LR: 0.000001628\n",
      "Epoch: 775        Loss did not change\n",
      "Epoch: 776        Loss did not change\n",
      "Epoch: 777        Lr was reduced to: 0.000001140\n",
      "Epoch: 778        Loss did not change\n",
      "Epoch: 779        Loss: 8305.3916  LR: 0.000001140\n",
      "Epoch: 780        Loss did not change\n",
      "Epoch: 781        Loss did not change\n",
      "Epoch: 782        Loss did not change\n",
      "Epoch: 783        Loss did not change\n",
      "Epoch: 784        Loss did not change\n",
      "Epoch: 785        Loss did not change\n",
      "Epoch: 786        Lr was reduced to: 0.000000798\n",
      "The step size is too small: 7.979226629761193e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "measure = pm.Measure(locations=l, weights=w, device=dev)\n",
    "opt = pm.Optimizer([measure], lr=1e-3)\n",
    "opt.minimize(KDENLLLoss, verbose=True, print_freq=1, max_epochs=1000, tol_const=1e-2)\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "mu=0 #Create true values\n",
    "sigma=1\n",
    "xs = l.detach()\n",
    "y=1/(np.sqrt(2*np.pi)*sigma)*torch.exp(-(xs+2-mu)**2/(2*sigma**2))\n",
    "y/=sum(y) #Normalize\n",
    "\n",
    "\n",
    "measure.visualize()\n",
    "plt.bar(l-0.1, torch.sum(kde_mat, dim=0)/torch.sum(kde_mat), zorder=0, width=0.1)\n",
    "plt.scatter(xs, y, zorder=2)\n",
    "plt.legend(['KDE', 'PDF of true distribution','Measure'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Sergei'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mSergei\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_measure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01ms\u001b[39;00m\n\u001b[1;32m      3\u001b[0m mes \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mTorchMeasure(l, w)\n\u001b[1;32m      4\u001b[0m opt \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mMeasureMinimizer(mes, KDENLLLoss, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-1\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Sergei'"
     ]
    }
   ],
   "source": [
    "import torch_measure as s\n",
    "\n",
    "mes = s.TorchMeasure(l, w)\n",
    "opt = s.MeasureMinimizer(mes, KDENLLLoss, learning_rate=1e-1)\n",
    "opt.minimize()\n",
    "\n",
    "\n",
    "plt.scatter(xs, y, zorder=2)\n",
    "plt.bar(l, mes.weights.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
