{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbcbe63-a9df-49d3-a608-55198c5ac4e5",
   "metadata": {},
   "source": [
    "# The fundamentals of PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c9eb56-ab6f-4a67-8d73-6ce4f0756571",
   "metadata": {},
   "source": [
    "Resource for reading: https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c72ed95-8de3-4114-924a-163414d27a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ebf850-e7d9-44a8-94cc-afb134315d66",
   "metadata": {},
   "source": [
    "## PyTorch Tensors\n",
    "    - fundmental building blocks, usually created behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0b83c9-ba2d-4ee5-8453-efc5b38aa857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating tensor\n",
    "\n",
    "# Scalar tensor\n",
    "scalar = torch.tensor(7)\n",
    "\n",
    "# Get tensor as Python int\n",
    "scalar.item() \n",
    "# Get tensor dimension (number of brackets)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3b65eb-e128-460d-a399-3f30ed183d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector tensor\n",
    "vector = torch.tensor([7, 7])\n",
    "\n",
    "# Get tensor shape\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb3a61e-3a39-4068-810c-0f778478dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX tensor\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 5]])\n",
    "# Indexing\n",
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdff439b-10a4-4f97-8b80-5ea63734f853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 7],\n",
    "                        [2, 5, 4]]])\n",
    "TENSOR.ndim, TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ee5f71-e470-494f-bd2f-14f67f3b95d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8364, 0.9553, 0.6310, 0.1325],\n",
       "        [0.5200, 0.2362, 0.4182, 0.9037],\n",
       "        [0.4784, 0.7252, 0.4921, 0.5970]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random tensors \n",
    "## - often start of NN (iterativley updating the random numbers)\n",
    "\n",
    "# Create random tensor of size ([3, 4]) -> (2-dimensional)\n",
    "random_tensor = torch.rand(3, 4) # number of parameters = ndim\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19550f25-b4b0-46c4-a4c1-941d7dcd4c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almost any data can be represented by tensors\n",
    "# Create random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channels (R, G, B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bacd94-24d1-484c-b656-186dd352dc91",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0a40d2-0685-4823-9612-e3812c4b2b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create all-zeros or all-ones tensor\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "ones  = torch.ones(size=(3,4))\n",
    "zeros, ones, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77b7d2-007b-4fde-8b87-798fe93f19db",
   "metadata": {},
   "source": [
    "### Range of tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8a15b8-a3e8-473f-95de-763fb409383c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create range of tensors\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df4939c-7350-4a5f-bfbd-aae7462b4895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b3bad-899e-436a-96ed-dbfff8bee5c5",
   "metadata": {},
   "source": [
    "### Tensor Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cb883f0-b311-474c-aced-24e086393b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float tensor - 32 is single-precision, detail/precision when computing\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                              dtype=None, # datatype of tensor (float32, float16, float64)\n",
    "                              device=None, # what device the tensor is on (default is \"cpu\")\n",
    "                              requires_grad=False) # whether or not to track gradients with this tensors operations\n",
    "float_16_tensor = float_32_tensor.type(torch.float16) # or torch.half"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55221e7-fbe6-46bc-b91d-0baa56531db8",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with `PyTorch` & deep learning (often has to do with matrix multiplication):\n",
    "1. Tensors are not right datatype\n",
    "2. Tensors are not right shape\n",
    "3. Tensors are not on the right device - tensors might live on different devices (e.g. gpu & cpu)\n",
    "\n",
    "How to get that info:\n",
    "1. `tensor.dtype`\n",
    "2. `tensor.shape` or `tensor.size`\n",
    "3. `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c418d4cd-af88-475d-9cf7-04fdaada382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:  tensor([3., 6., 9.])\n",
      "Datatype:  torch.float32\n",
      "Shape/Size:  torch.Size([3]) torch.Size([3])\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print('Tensor: ', float_32_tensor)\n",
    "print('Datatype: ', float_32_tensor.dtype)\n",
    "print('Shape/Size: ', float_32_tensor.shape, float_32_tensor.size())\n",
    "print('Device: ', float_32_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084eb2d-b2c1-4f37-90f5-dae913b3edce",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Division\n",
    "* Multiplication (element-wise)\n",
    "* Matrix multiplication\n",
    "\n",
    "Tensor aggregations include:\n",
    "* Min, Max, Mean, Sum etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9a8803-77ed-465a-8ead-2cc07e3118a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor, basic operations\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor1 + 10\n",
    "# tensor1 - 10\n",
    "# tensor1 / 10\n",
    "# tensor1 * 10 (element-wise)\n",
    "# In-built function: e.g. torch.add(), torch.mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3622ac0a-0354-4e55-9bb9-769c1a0a9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 40,  46],\n",
      "        [ 94, 109]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication (dot product, @)\n",
    "tensor2 = torch.tensor([[4, 5],\n",
    "                        [6, 7],\n",
    "                        [8, 9]])\n",
    "print(tensor1 @ tensor2) # or torch.mm(tensor1, tensor2)\n",
    "\n",
    "# Main rules when multiplying tensors:\n",
    "# - Inner dimensions must match (m x n @ n x k)\n",
    "# - The resulting has shape of outer dimension (m x k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eeea1ab-079d-43e2-acbe-68c5181e3f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To alter shape of tensors we can transpose the tensors\n",
    "tensor1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b7f982-b4c8-4c3b-a0e7-052b00fef3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding min, max and sum of tensor (tensor aggregation -> elements becomes fewer)\n",
    "min  = torch.min(tensor1).item()\n",
    "max  = torch.max(tensor1).item()\n",
    "mean = torch.mean(tensor1.type(torch.float32)).item() # need to convert to right datatype to use mean-function\n",
    "sum  = torch.sum(tensor1).item() \n",
    "\n",
    "# Finding the indecies for those values (usefull when using soft_max-function)\n",
    "ind_min = tensor1.argmin().item()\n",
    "ind_max = tensor1.argmax().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22445f-4854-4e1f-9699-eaa4323a0bda",
   "metadata": {},
   "source": [
    "#### Layout operations on tensors:\n",
    "* **Reshaping** - reshapes an input tensor into a defined shape\n",
    "* **View** - return a view of an input tensor of certain shape but keep memory as the original tensor\n",
    "* **Stacking** - combine multiple tensors: \n",
    "                   - on top of each other (vstack or dim=0),\n",
    "                   - side by side (hstack or dim=1) or\n",
    "                   - with regards to a given dimension (dim=...)\n",
    "* **Squeez** - removes all \"1\" dimensions from an input tensor\n",
    "* **Unsqueez** - adds a \"1\" dimension to a target tensor (dim must be specified)\n",
    "* **Permute** - rearranges the dimensions of a target tensor in a specified order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ce5a41-a8b3-4c6f-953f-583ae24e1d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " torch.Size([12]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 13.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e064a07-e390-4e0d-91d1-a3a0231b77fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.]],\n",
       "\n",
       "        [[ 7.,  8.,  9.],\n",
       "         [10., 11., 12.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension with torch.reshape \n",
    "# - if compatible with original dimensions \n",
    "# - That is: product in reshape function must\n",
    "#            be the same as the size for input tensor\n",
    "x_reshaped = x.reshape(2, 2, 3)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afb51df8-b0f3-4274-92de-dcdc891d0f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]),\n",
       " torch.Size([1, 12]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view - similar to reshape but here z\n",
    "#                   shares memory with original tensor x\n",
    "# This means that changing z changes x (shared memory)\n",
    "z = x.view(1, 12)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adfb605a-474f-4f59-8639-4342f447203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.],\n",
       "         [11., 11., 11., 11.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[[[ 1.,  2.,  3.],\n",
       "           [ 1.,  2.,  3.]],\n",
       " \n",
       "          [[ 4.,  5.,  6.],\n",
       "           [ 4.,  5.,  6.]]],\n",
       " \n",
       " \n",
       "         [[[ 7.,  8.,  9.],\n",
       "           [ 7.,  8.,  9.]],\n",
       " \n",
       "          [[10., 11., 12.],\n",
       "           [10., 11., 12.]]]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors with respect to different dimensions\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_reshaped_stacked = torch.stack([x_reshaped, x_reshaped], dim=2)\n",
    "x_stacked, x_reshaped_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d99080ba-44a6-4c30-a8ca-8de6d81a0298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]) \n",
      " torch.Size([1, 12])\n",
      "\n",
      " After squeezing:\n",
      "\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]) \n",
      " torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze, unsqueeze and permutation\n",
    "z_squeezed = z.squeeze()\n",
    "print(z, '\\n', z.shape)\n",
    "print('\\n After squeezing:\\n')\n",
    "print(z_squeezed, '\\n', z_squeezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c014f70-b058-40e9-989d-2e8f2deb903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]) \n",
      " torch.Size([1, 12])\n",
      "\n",
      " After unsqueezing:\n",
      "\n",
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]]) \n",
      " torch.Size([1, 1, 12])\n"
     ]
    }
   ],
   "source": [
    "z_unsqueezed = z.unsqueeze(dim=0)\n",
    "print(z, '\\n', z.shape)\n",
    "print('\\n After unsqueezing:\\n')\n",
    "print(z_unsqueezed, '\\n', z_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8d34d1f-f2d9-48d4-b1fc-e000fdc77de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3])\n",
      "\n",
      " After permuting: \n",
      "\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Permuting something is also a view of something\n",
    "# This means x_original and x_permuted will share memory \n",
    "# i. e. changing x_original will change x_permuting\n",
    "x_original = torch.rand(size=(224, 224, 3)) # original: (height, width, color channel) i. e. image data\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # permuted: (color channel, height, width)\n",
    "print(x_original.shape)\n",
    "print('\\n After permuting: \\n')\n",
    "print(x_permuted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e2eed-322f-44c9-b2cd-743005b18bb6",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "Indexing with `PyTorch` is very similar to indexing with `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdc68e8e-620b-4214-83f8-51e2a18dd5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor\n",
    "tensor3 = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "579257ba-21ed-4114-9583-fb7214a96aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outer bracket \n",
    "tensor3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ec50282-ba4c-4f76-bba4-284b0838b08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Middle bracket (second row)\n",
    "tensor3[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8784be88-df4b-4076-b8c0-e1d6463897c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inner bracket (first row, third element)\n",
    "tensor3[0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2c779d4-3fab-4d2a-ba35-db54fae6c512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing\n",
    "# Everything in first dimension and then first element in \n",
    "# second dimension gives us:\n",
    "tensor3[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53e81c11-76f8-4ca8-8fff-e8b40070e497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element in first dimension and then everything in \n",
    "# second dimension gives us the same:\n",
    "tensor3[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dedca4b0-1837-4f66-a808-dfb6f4a293eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element in first dimension and everything in \n",
    "# second dimension and second element in third dimension \n",
    "# gives us:\n",
    "tensor3[0][:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edd41b56-d1cd-4dd3-bd4d-e16826672c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 8, 9]) \n",
      "\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "# First element in first dimension and third element in \n",
    "# second dimension and everything in third dimension \n",
    "# gives us the third row:\n",
    "print(tensor3[0][2][:], '\\n')\n",
    "\n",
    "# Note: With our tensor tensor3[:] and tensor3[0] returns almost the \n",
    "# same thing since tensor3's dimension is [1, 3, 3] (i. e. in it's \n",
    "# first dimension it only has one element). However tensor3[0] will\n",
    "# slice the tensor so that the outer brackets disappear while \n",
    "# tensor3[:] will keep the outer brackets:\n",
    "print(tensor3[0])\n",
    "print(tensor3[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e450cdf-1235-4b45-b5ba-e5bcfda540e8",
   "metadata": {},
   "source": [
    "### PyTorch & NumPy\n",
    "`PyTorch` builds upon `NumPy` and so `PyTorch` has functionality to interact with `NumPy`:\n",
    "* Data in `NumPy` -> `PyTorch` tensor: `torch.from_numpy(ndarray)`\n",
    "* `PyTorch` tensor -> `Numpy` array: `torch.Tensor.numpy()` \n",
    "\n",
    "**Note:** The default datatype for a `NumPy` array is float64 while the default datatype for a `PyTorch` tensor is float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cdc0346-883d-40be-a099-9ed3260cea37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# From NumPy array to tensor \n",
    "nparray  = np.arange(1.0, 10.0)\n",
    "pytensor = torch.from_numpy(nparray)\n",
    "nparray.dtype, pytensor.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba3d4eee-f0f4-42ab-bfd3-06a277493e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, dtype('float32'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From tensor to NumPy array\n",
    "pytensor2 = torch.ones(7)\n",
    "numpy_array = pytensor2.numpy()\n",
    "pytensor2.dtype, numpy_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379174e-3a3a-42fc-b1db-a719ee14a9fa",
   "metadata": {},
   "source": [
    "#### Reproducability \n",
    "Briefley how a NN learns:\n",
    "\n",
    "\"start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> iterate\"\n",
    "\n",
    "We don't want completely random (sudo-random) numbers in tensors. We need our experiment to be somewhat reproduceable. \n",
    "\n",
    "To reduce randomness of NN and PyTorch we introduce the concept of a **random seed**.\n",
    "\n",
    "The **random seed** essentialy \"flavours\" the randomness.\n",
    "\n",
    "Resource: https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e59c89a-1e75-43fe-9381-c111cb189794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aff67a4a-03ac-45e8-abf7-66aeee658ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Lets make some random but reproducable tensors\n",
    "# Set random seed (here in notebook we have to set seed before every function call)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)\n",
    "\n",
    "# Tensors still random but reproducable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8119f48-2997-4619-ba72-7cdf3393cf81",
   "metadata": {},
   "source": [
    "#### Running objects on GPUs (faster computations)\n",
    "Getting a GPU:\n",
    "* Use Google Colab Pro\n",
    "* Use your own (requires a GPU driver, CUDA + NVIDIA) \n",
    "* Use cloud computing - GCP, AWS, Azure (renting)\n",
    "\n",
    "Resource: https://pytorch.org/get-started/locally/\n",
    "\n",
    "Resource: https://pytorch.org/docs/stable/notes/cuda.html#best-practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c50d6096-a419-43f8-a3ea-53519db0d62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking for GPU access with PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a176d292-47d8-4473-8c29-c85d1e3b61b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Counting number of devices/GPUs available\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ad46dcd-d297-4682-852c-241596f9747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensor (and models) to target device (default is on cpu)\n",
    "tensor_on_CPU = torch.tensor([1, 2, 3])\n",
    "tensor_on_GPU = tensor_on_CPU.to(device)\n",
    "\n",
    "# And moving back on CPU to be able to convert to numpy array\n",
    "tensor_back_on_cpu = tensor_on_GPU.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
